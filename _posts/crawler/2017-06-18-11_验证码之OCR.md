---
layout: post
categories: [crawler]
title: 验证码之OCR
date: 2007-06-18
author: TTyb
desc: "11.验证码之OCR"
showdate: 2017-06-18
---

在爬虫的过程中，可能都会遇到一个很头疼的问题： **验证码** 。弹出验证码是 **反爬虫** 的一种方式，主要是由于这些原因：

>1. 抓取频率太高
>2. 爬虫未伪装
>3. 网站限制访问次数

对于第一种情况，如果爬虫的要求不是很高的话，或者网站很奇葩，一定需要时间间隔，例如：

<p style="text-align:center"><img  src="/img/crawler11/result1.jpg" class="img-responsive" style="display: block; margin-right: auto; margin-left: auto;"></p>

在抓取这类网站的时候，可以在每个抓取周期里面加上一个暂停，每次抓取都暂停 `3` 秒：

~~~ruby
import time
time.sleep(3)
~~~

一般就可以杜绝这种情况的发生了。什么时候才算是爬虫的要求不高？爬虫可以分为两类：

>1. 主动式爬虫
>2. 被动式爬虫

主动式爬虫指的是，输入一个关键词，然后根据这个关键词去抓取相关的信息下来。这类的爬虫一般要求的数据量少，对爬虫要求没那么高，一般的爬虫工作者完全能胜任此类要求。

被动式爬虫指的是，实时监测网站更新的内容，一旦发现更新就将其抓取下来，这类一般出现在新闻公司。还有一种是要求将网站某一种类的信息全部抓取下来，这一般出现在电商公司。例如在每天将将淘宝女装的信息抓取到数据库，方便运营人员统计分析。被动式爬虫一般要求的数据量大，难度相对会高一些，几本也算是爬虫界的分水岭。

言归正传，在爬虫的时候遇到验证码怎么办？在条件不太富裕的情况下，可以选择更换 `UA` 来避免爬虫被发现的概率。作者收集了几百个 **头部UA** ，下载链接：

<a href="/code/crawler11/头部UA.txt" target="_blank">头部UA.txt</a>

抓取前筛选出一部分想要的 `UA` ，按行读取：

~~~ruby
#!/usr/bin/python3.4
# -*- coding: utf-8 -*-

fileua = open("头部UA.txt")
uas = fileua.readlines()
for item in uas:
    ua = item.strip()
    print(ua)
~~~

每次抓取构造 `header` 的时候使用新的 `UA` ：

~~~ruby
header = {
        "User-Agent": ua,
    }
~~~

这样被发现为爬虫的概率降低了，弹出验证码的概率也低了。

但是一般这样还是不够，如果再加上伪装 `cookie` 就更完美了，可是如何获取 `cookie` 呢？一般在伪装头部的时候会有一个字段 `host` ， 构造一个简单的头部访问 `host` ，就可以得到 `cookie` 了，再携带这个 `cookie` 访问想要抓取的网址：

~~~ruby
#!/usr/bin/python3.4
# -*- coding: utf-8 -*-

import requests
url = "https://www.baidu.com/"

session = requests.session()
req = session.get(url)
cookie = requests.utils.dict_from_cookiejar(req.cookies)
print(cookie)
~~~

一般携带 `cookie` 后访问，还需要验证码的概率会降低一些。可是，还是需要验证码怎么办？本文的重点来了，使用 `orc` 识别简单的字母文字验证码！

在使用 `tesseract-ocr` 之前需要安装一些库：

>1. pip3 install pyocr
>2. pip3 install pillow 或者 easy_install Pillow
>3. 安装tesseract-ocr：http://jaist.dl.sourceforge.net/project/tesseract-ocr-alt/tesseract-ocr-setup-3.02.02.exe，安装在C:\Program Files\下
>4. 要求python默认安装在C盘
>5. 找到 pytesseract.py 更改 tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'

如果出现错误：

~~~ruby
'str' does not support the buffer interface 
~~~

将 `pytesseract.py` 中的下面语句更换：

~~~ruby
lines = error_string.splitlines()
#error_lines = tuple(line for line in lines if line.find('Error') >= 0)
error_lines = tuple(line.decode('utf-8') for line in lines if line.find(b'Error') >= 0)
if len(error_lines) > 0:
	return '\n'.join(error_lines)
else:
	return error_string.strip()
~~~

识别数字验证码：

<p style="text-align:center"><img  src="/img/crawler11/result2.jpg" class="img-responsive" style="display: block; margin-right: auto; margin-left: auto;"></p>

~~~ruby
# !/usr/bin/python3.4
# -*- coding: utf-8 -*-

import pytesseract
from PIL import Image

image = Image.open('../jpg/code.png')
code = pytesseract.image_to_string(image)
print(code)
~~~

完美识别：

<p style="text-align:center"><img  src="/img/crawler11/result3.jpg" class="img-responsive" style="display: block; margin-right: auto; margin-left: auto;"></p>

# 源码

<a href="/code/crawler11/crawler11.py" target="_blank">crawler11.py</a>
